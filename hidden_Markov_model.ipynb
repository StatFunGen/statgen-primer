{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8e41cf",
   "metadata": {},
   "source": [
    "# Hidden Markov Model (HMM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6cafa5",
   "metadata": {},
   "source": [
    "A Hidden Markov Model (HMM) is a statistical model for sequential data where unobservable states (e.g., underlying ancestry) evolve over time according to a Markov chain, and at each time point we observe noisy or indirect measurements that depend on the current hidden state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99dda04",
   "metadata": {},
   "source": [
    "# Graphical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69e867",
   "metadata": {},
   "source": [
    "![fig](./cartoons/fig.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389d462",
   "metadata": {},
   "source": [
    "# Key Formula\n",
    "\n",
    "The complete probability of any sequence of hidden states and observations in an HMM is given by:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(z_{1:T}, x_{1:T}) = \\mathbb{P}(z_1) \\prod_{t=2}^{T} \\mathbb{P}(z_t | z_{t-1}) \\prod_{t=1}^{T} \\mathbb{P}(x_t | z_t)\n",
    "$$\n",
    "\n",
    "- $z_t$ = hidden state at time $t$ (what's happening behind the scenes)\n",
    "- $x_t$ = observation at time $t$ (what you can actually see)\n",
    "- $z_{1:T}$ = sequence of hidden states from time 1 to $T$\n",
    "- $x_{1:T}$ = sequence of observations from time 1 to $T$\n",
    "- $T$ = total number of time steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec5448",
   "metadata": {},
   "source": [
    "# Technical Details\n",
    "\n",
    "## Markov Chain\n",
    "\n",
    "A Markov chain is a sequence of random variables $z_1, z_2, \\ldots, z_T$ where the future state depends only on the current state, not on the history:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(z_{t+1} | z_1, z_2, \\ldots, z_t) = \\mathbb{P}(z_{t+1} | z_t)\n",
    "$$\n",
    "\n",
    "This is the **Markov property**. The chain is fully specified by initial distribution $\\mathbb{P}(z_1)$ and transition probabilities $\\mathbb{P}(z_{t+1} | z_t)$.\n",
    "\n",
    "An HMM extends this by adding observations: the states $z_t$ are hidden (unobservable), but at each time $t$ we observe $x_t$ that depends only on the current hidden state $z_t$. This is called **output independence**.\n",
    "\n",
    "## Inference Problem\n",
    "\n",
    "Given a sequence of observations $x_{1:T}$, we want to infer the hidden states. Specifically, we want to compute the posterior distribution $\\mathbb{P}(z_t | x_{1:T})$ for each time $t$. The forward-backward algorithm solves this efficiently using dynamic programming.\n",
    "\n",
    "## Forward Probability\n",
    "\n",
    "The forward probability accumulates information from past observations.\n",
    "\n",
    "**Definition:**\n",
    "\n",
    "$$\n",
    "\\alpha_t(k) := \\mathbb{P}(z_t = k, x_{1:t})\n",
    "$$\n",
    "\n",
    "Joint probability of state $k$ at time $t$ and all past observations.\n",
    "\n",
    "**Forward Recursion:**\n",
    "\n",
    "$$\n",
    "\\alpha_{t+1}(k) = \\mathbb{P}(x_{t+1} | z_{t+1} = k) \\sum_{j} \\alpha_t(j) \\cdot \\mathbb{P}(z_{t+1} = k | z_t = j)\n",
    "$$\n",
    "\n",
    "## Backward Probability\n",
    "\n",
    "The backward probability accumulates information from future observations.\n",
    "\n",
    "**Definition:**\n",
    "\n",
    "$$\n",
    "\\beta_t(k) := \\mathbb{P}(x_{t+1:T} | z_t = k)\n",
    "$$\n",
    "\n",
    "Probability of all future observations given state $k$ at time $t$.\n",
    "\n",
    "**Backward Recursion:**\n",
    "\n",
    "$$\n",
    "\\beta_t(k) = \\sum_{j} \\mathbb{P}(z_{t+1} = j | z_t = k) \\cdot \\mathbb{P}(x_{t+1} | z_{t+1} = j) \\cdot \\beta_{t+1}(j)\n",
    "$$\n",
    "\n",
    "## Posterior Distribution\n",
    "\n",
    "By the Markov property, conditioning on $z_t$ makes past and future observations independent:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(z_t = k, x_{1:T}) = \\mathbb{P}(z_t = k, x_{1:t}) \\cdot \\mathbb{P}(x_{t+1:T} | z_t = k) = \\alpha_t(k) \\cdot \\beta_t(k)\n",
    "$$\n",
    "\n",
    "Thus, the posterior distribution is:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(z_t = k | x_{1:T}) = \\frac{\\alpha_t(k) \\cdot \\beta_t(k)}{\\sum_{k'} \\alpha_t(k') \\cdot \\beta_t(k')}\n",
    "$$\n",
    "\n",
    "This answers: \"Given all observations, what is the probability we were in state $k$ at time $t$?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed385ec",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5cb47c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aaa5b7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Clear the environment\n",
    "rm(list = ls())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79ffec",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
