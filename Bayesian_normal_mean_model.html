
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Bayesian Normal Mean Model &#8212; Statistical backgrounds for gene mapping</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Bayesian_normal_mean_model';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Bayesian Multivariate Normal Mean Model" href="Bayesian_multivariate_normal_mean_model.html" />
    <link rel="prev" title="p-value and Bayesian Hypothesis Testing" href="p_value.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="README.html">
  
  
  
  
  
  
    <p class="title logo__title">Statistical backgrounds for gene mapping</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Popular Topics and Related Notebooks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="notations.html">Notations</a></li>
<li class="toctree-l1"><a class="reference internal" href="popular_topics.html">Popular Topics in Statistical Genetics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="genotype_coding.html">Genotype Coding</a></li>






<li class="toctree-l1"><a class="reference internal" href="minor_allele_frequency.html">Minor Allele Frequency</a></li>





<li class="toctree-l1"><a class="reference internal" href="Hardy_Weinberg_equilibrium.html">Hardy-Weinberg Equilibrium</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Correlation Between Variants</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="linkage_disequilibrium.html">Linkage Disequilibrium</a></li>






<li class="toctree-l1"><a class="reference internal" href="linkage_disequilibrium_score.html">Linkage Disequilibrium Score</a></li>






</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Correlation Between Individuals</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="genetic_relationship_matrix.html">Genetic Relationship Matrix</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Latent Structures in Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="factor_analysis.html">Factor Analysis</a></li>





<li class="toctree-l1"><a class="reference internal" href="principal_component_analysis.html">Principal Component Analysis</a></li>







<li class="toctree-l1"><a class="reference internal" href="hidden_Markov_model.html">Hidden Markov Model (HMM)</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Fixed Effects Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ordinary_least_squares.html">Ordinary Least Squares</a></li>






<li class="toctree-l1"><a class="reference internal" href="odds_ratio.html">Odds Ratio</a></li>






<li class="toctree-l1"><a class="reference internal" href="marginal_joint_effects.html">Marginal and Joint Effects</a></li>






<li class="toctree-l1"><a class="reference internal" href="summary_statistics.html">Summary Statistics</a></li>






</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Random Effects Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="proportion_of_variance_explained.html">Proportion of Variance Explained and Heritability</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Mixed Model</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="linear_mixed_model.html">Linear Mixed Model</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Covariates</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="confounder.html">Confounder</a></li>





<li class="toctree-l1"><a class="reference internal" href="collider.html">Collider</a></li>





<li class="toctree-l1"><a class="reference internal" href="mediator.html">Mediator</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Meta-analysis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="meta_analysis_fixed_effect.html">Meta-Analysis Fixed Effect</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Likelihood</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="likelihood.html">Likelihood</a></li>






<li class="toctree-l1"><a class="reference internal" href="maximum_likelihood_estimation.html">Maximum Likelihood Estimation</a></li>






<li class="toctree-l1"><a class="reference internal" href="likelihood_ratio.html">Likelihood Ratio</a></li>







</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Versus Frequentist</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Bayesian_frequentist.html">Bayesian and Frequentist</a></li>
<li class="toctree-l1"><a class="reference internal" href="Bayes_rule.html">Bayes Rule</a></li>






<li class="toctree-l1"><a class="reference internal" href="Bayes_factor.html">Bayes Factor</a></li>





<li class="toctree-l1"><a class="reference internal" href="p_value.html">p-value and Bayesian Hypothesis Testing</a></li>







</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Regression Models</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Bayesian Normal Mean Model</a></li>






<li class="toctree-l1"><a class="reference internal" href="Bayesian_multivariate_normal_mean_model.html">Bayesian Multivariate Normal Mean Model</a></li>






</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Multiple Bayesian Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Bayesian_model_comparison.html">Bayesian Model Comparison</a></li>






<li class="toctree-l1"><a class="reference internal" href="Bayesian_mixture_model.html">Bayesian Mixture Model</a></li>






</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Bayesian_normal_mean_model.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bayesian Normal Mean Model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Bayesian Normal Mean Model</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#graphical-summary">Graphical Summary</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#key-formula">Key Formula</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-details">Technical Details</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bayesian-perspective-uncertainty-as-random-variables">The Bayesian Perspective: Uncertainty as Random Variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-assumptions">Model Assumptions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-distribution-quantifying-our-uncertainty">Prior Distribution: Quantifying Our Uncertainty</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-what-we-can-condition-on">Likelihood: What We Can Condition On</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-distribution-conditioning-on-everything-available">Posterior Distribution: Conditioning on Everything Available</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation-as-weighted-average">Interpretation as Weighted Average</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-this-makes-sense">Why This Makes Sense</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#related-topics">Related Topics</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-simulated-data">Generate Simulated Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-normal-mean-model-setup">Bayesian Normal Mean Model Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-both-variances-from-data">Estimating Both Variances from Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-the-posterior">Computing the Posterior</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#supplementary">Supplementary</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Graphical Summary</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="bayesian-normal-mean-model">
<h1>Bayesian Normal Mean Model<a class="headerlink" href="#bayesian-normal-mean-model" title="Link to this heading">#</a></h1>
<p>The Bayesian normal mean model treats the <strong>unknown</strong> mean parameter as a <strong>normally distributed</strong> random variable reflecting our <strong>uncertainty</strong>, then updates this normal distribution by <strong>conditioning on observed data</strong> to yield a posterior normal distribution with <strong>reduced uncertainty</strong>.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="graphical-summary">
<h1>Graphical Summary<a class="headerlink" href="#graphical-summary" title="Link to this heading">#</a></h1>
<p><img alt="Fig" src="_images/Slide26.png" /></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="key-formula">
<h1>Key Formula<a class="headerlink" href="#key-formula" title="Link to this heading">#</a></h1>
<p>Under the Bayesian regression setting, we have</p>
<div class="math notranslate nohighlight">
\[
\mathbf{Y} = \mathbf{X} \beta + \boldsymbol{\varepsilon}, \quad \boldsymbol{\varepsilon} \sim \mathcal{N}(0, \sigma^2 \mathbf{I})
\]</div>
<p>where we place a <strong>prior distribution</strong> on the regression coefficient: <span class="math notranslate nohighlight">\(\beta \sim \mathcal{N}(\beta_0, \sigma_0^2)\)</span>.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \mathbf{Y} \in \mathbb{R}^{N \times 1} \)</span>: phenotype vector</p></li>
<li><p><span class="math notranslate nohighlight">\( \mathbf{X} \in \mathbb{R}^{N \times 1} \)</span>: genotype vector (e.g., 0, 1, 2 for additive coding)</p></li>
<li><p><span class="math notranslate nohighlight">\( \beta \in \mathbb{R} \)</span>: a scalar, genetic effect size (regression coefficient)</p></li>
<li><p><span class="math notranslate nohighlight">\( \boldsymbol{\varepsilon} \in \mathbb{R}^{N \times 1} \)</span>: residual error, assumed i.i.d. Gaussian</p></li>
</ul>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="technical-details">
<h1>Technical Details<a class="headerlink" href="#technical-details" title="Link to this heading">#</a></h1>
<section id="the-bayesian-perspective-uncertainty-as-random-variables">
<h2>The Bayesian Perspective: Uncertainty as Random Variables<a class="headerlink" href="#the-bayesian-perspective-uncertainty-as-random-variables" title="Link to this heading">#</a></h2>
<p>In Bayesian statistics, parameters are not fixed unknown constants but <strong>random variables representing our uncertainty</strong>. This fundamental shift occurs because we recognize that we can never condition on everything that might influence a parameter’s true value.</p>
<p><strong>Key insight</strong>: When we cannot condition on something (because it’s unobserved or unknown), we treat it as a random variable with a probability distribution that quantifies our uncertainty.</p>
</section>
<section id="model-assumptions">
<h2>Model Assumptions<a class="headerlink" href="#model-assumptions" title="Link to this heading">#</a></h2>
<p>In the Bayesian normal mean model, we treat uncertainty systematically by making everything we cannot fully condition on into a random variable:</p>
<div class="math notranslate nohighlight">
\[
Y_i \sim \mathcal{N}(X_i\beta, \sigma^2) \quad \text{for } i = 1, 2, \ldots, N
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta\)</span> is <strong>not</strong> a fixed unknown constant, but a <strong>random variable</strong> representing our uncertainty about the genetic effect</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma^2\)</span> is the known variance (we condition on this)</p></li>
<li><p><span class="math notranslate nohighlight">\(X_i\)</span> is the genotype value (fixed and observed - we condition on this)</p></li>
</ul>
<p>The key insight: <strong>Since we cannot condition on the true value of <span class="math notranslate nohighlight">\(\beta\)</span> (we don’t know it), we treat it as random.</strong></p>
</section>
<section id="prior-distribution-quantifying-our-uncertainty">
<h2>Prior Distribution: Quantifying Our Uncertainty<a class="headerlink" href="#prior-distribution-quantifying-our-uncertainty" title="Link to this heading">#</a></h2>
<p>Since we cannot condition on the true value of <span class="math notranslate nohighlight">\(\beta\)</span>, we express our uncertainty through a probability distribution:</p>
<div class="math notranslate nohighlight">
\[
\beta \sim \mathcal{N}(\beta_0, \sigma_0^2)
\]</div>
<p>This prior distribution represents:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta_0\)</span>: Our best guess about the effect (what we’d expect if we had no data)</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_0^2\)</span>: How uncertain we are about this guess (larger variance = more uncertainty)</p></li>
</ul>
<p><strong>Key insight</strong>: This isn’t saying <span class="math notranslate nohighlight">\(\beta\)</span> “is random” in nature - it’s saying <strong>our knowledge about <span class="math notranslate nohighlight">\(\beta\)</span> is uncertain</strong> because we cannot condition on everything that determines the true effect.</p>
<p>The probability density function reflects this uncertainty:</p>
<div class="math notranslate nohighlight">
\[
p(\beta) \propto \exp\left(-\frac{(\beta - \beta_0)^2}{2\sigma_0^2}\right)
\]</div>
</section>
<section id="likelihood-what-we-can-condition-on">
<h2>Likelihood: What We Can Condition On<a class="headerlink" href="#likelihood-what-we-can-condition-on" title="Link to this heading">#</a></h2>
<p>The likelihood represents what we <strong>can</strong> condition on - the observed data given our uncertain parameter:</p>
<div class="math notranslate nohighlight">
\[
Y_i\mid\beta, \sigma^2 \sim \mathcal{N}(X_i\beta, \sigma^2) \quad \text{for } i = 1, 2, \ldots, N
\]</div>
<p>For all observations, the likelihood is:</p>
<div class="math notranslate nohighlight">
\[
p(\mathbf{Y}\mid\beta) \propto \exp\left(-\frac{1}{2\sigma^2} \sum_{i=1}^N (Y_i - X_i\beta)^2\right)
\]</div>
<p>This says: “If we knew <span class="math notranslate nohighlight">\(\beta\)</span> (could condition on it), this is how likely our data would be.”</p>
</section>
<section id="posterior-distribution-conditioning-on-everything-available">
<h2>Posterior Distribution: Conditioning on Everything Available<a class="headerlink" href="#posterior-distribution-conditioning-on-everything-available" title="Link to this heading">#</a></h2>
<p>Using Bayes’ theorem, we condition on all available information (the observed data) to update our uncertainty:</p>
<div class="math notranslate nohighlight">
\[
p(\beta|\mathbf{Y}) \propto p(\mathbf{Y}|\beta) p(\beta)
\]</div>
<p><strong>This is the essence of Bayesian thinking</strong>: Start with our uncertainty (prior), observe data, then update our uncertainty by conditioning on what we’ve learned.</p>
<p>The posterior distribution follows a normal distribution:</p>
<div class="math notranslate nohighlight">
\[
\beta \mid \mathbf{Y} \sim \mathcal{N}\left( \beta_1, \sigma_1^2 \right)
\]</div>
<p>where the parameters are:</p>
<div class="math notranslate nohighlight">
\[
\beta_1 = \frac{\frac{1}{\sigma^2} \sum_{i=1}^N X_i Y_i + \frac{1}{\sigma_0^2} \beta_0}{\frac{1}{\sigma^2} \sum_{i=1}^N X_i^2 + \frac{1}{\sigma_0^2}}, \quad \sigma_1^2 = \frac{1}{\frac{1}{\sigma^2} \sum_{i=1}^N X_i^2 + \frac{1}{\sigma_0^2}}
\]</div>
<p>Notice: <span class="math notranslate nohighlight">\(\sigma_1^2 &lt; \sigma_0^2\)</span> always - <strong>conditioning on data reduces our uncertainty</strong>.</p>
<section id="interpretation-as-weighted-average">
<h3>Interpretation as Weighted Average<a class="headerlink" href="#interpretation-as-weighted-average" title="Link to this heading">#</a></h3>
<p>The posterior mean can be rewritten as a <strong>weighted average</strong> of what we knew before (prior) and what we learned from data:</p>
<div class="math notranslate nohighlight">
\[
\beta_1 = w \cdot \frac{T_2}{T_1} + (1-w) \cdot \beta_0
\]</div>
<p>where: <span class="math notranslate nohighlight">\(w = \frac{\frac{T_1}{\sigma^2}}{\frac{T_1}{\sigma^2} + \frac{1}{\sigma_0^2}}\)</span></p>
<p>This shows how conditioning works in practice:</p>
<ul class="simple">
<li><p><strong>More data</strong> or <strong>lower measurement error</strong> (small <span class="math notranslate nohighlight">\(\sigma^2\)</span> or large <span class="math notranslate nohighlight">\(T_1\)</span>): <span class="math notranslate nohighlight">\(w \approx 1\)</span>, we trust the data more</p></li>
<li><p><strong>More prior uncertainty</strong> (large <span class="math notranslate nohighlight">\(\sigma_0^2\)</span>): <span class="math notranslate nohighlight">\(w \approx 1\)</span>, we let data dominate since our prior was vague</p></li>
<li><p><strong>Less prior uncertainty</strong> (small <span class="math notranslate nohighlight">\(\sigma_0^2\)</span>): <span class="math notranslate nohighlight">\(w \approx 0\)</span>, we stick closer to our prior beliefs</p></li>
<li><p><strong>Equal information</strong> (<span class="math notranslate nohighlight">\(\frac{T_1}{\sigma^2} = \frac{1}{\sigma_0^2}\)</span>): <span class="math notranslate nohighlight">\(w = 0.5\)</span>, equal weighting</p></li>
</ul>
<p>where <span class="math notranslate nohighlight">\(T_1 = \sum_{i=1}^N X_i^2\)</span> and <span class="math notranslate nohighlight">\(T_2 = \sum_{i=1}^N X_i Y_i\)</span> are the sufficient statistics.</p>
</section>
</section>
<section id="why-this-makes-sense">
<h2>Why This Makes Sense<a class="headerlink" href="#why-this-makes-sense" title="Link to this heading">#</a></h2>
<p><strong>Traditional thinking</strong>: “What’s the true value of this parameter?”<br />
<strong>Bayesian thinking</strong>: “What’s our uncertainty about this parameter (because we can never condition on everything that determines it), and how does new information update that uncertainty?”</p>
<p>This framework naturally handles situations where multiple sources of uncertainty exist, and where we want to systematically combine prior knowledge with observed data. The mathematical machinery ensures that conditioning on observed information always reduces uncertainty in a coherent way.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="related-topics">
<h1>Related Topics<a class="headerlink" href="#related-topics" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://statfungen.github.io/statgen-primer/ordinary_least_squares.html">ordinary least squares</a></p></li>
<li><p><a class="reference external" href="https://statfungen.github.io/statgen-primer/summary_statistics.html">summary statistics</a></p></li>
<li><p><a class="reference external" href="https://statfungen.github.io/statgen-primer/likelihood.html">likelihood</a></p></li>
<li><p><a class="reference external" href="https://statfungen.github.io/statgen-primer/maximum_likelihood_estimation.html">maximum likelihood estimation</a></p></li>
</ul>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="example">
<h1>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h1>
<p>Imagine you’re studying genetic effects across many variants. You don’t know the true effect size for any particular variant, but you have some intuition: <strong>most genetic effects are probably small, some are moderate, and very few are large</strong>.</p>
<p>This is fundamentally different from asking “Is the effect exactly 0, 0.5, or 1.0?” (which assumes a fixed effect) Instead, we’re saying: <strong>“The true effect itself is uncertain - it’s a random quantity drawn from some distribution.”</strong></p>
<p>This leads us naturally to a <strong>hierarchical model</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Level 1 (Data)</strong>: Each person’s phenotype depends on their genotype and the true effect</p></li>
<li><p><strong>Level 2 (Effect)</strong>: The true effect is itself random, drawn from a distribution</p></li>
<li><p><strong>Level 3 (Hyperparameters)</strong>: The parameters of that distribution are learned from data</p></li>
</ol>
<p>This example shows how to implement a <strong>Bayesian normal mean model</strong>, where we treat <span class="math notranslate nohighlight">\(\beta\)</span> as a continuous parameter with a prior distribution. Instead of probabilities for just three specific values, we get a complete posterior distribution showing how plausible every possible effect size is after combining our prior knowledge with the data.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
Y_i | \beta, \sigma^2 &amp;\sim \mathcal{N}(X_i \beta, \sigma^2) \quad \text{[observed data given effect]} \\
\beta | \sigma_0^2 &amp;\sim \mathcal{N}(0, \sigma_0^2) \quad \text{[effect is random]} \\
\sigma_0^2 &amp; \text{ is estimated from data} \quad \text{[uncertainty about uncertainty!]}
\end{align}
\end{split}\]</div>
<p>This isn’t just philosophical - it’s practical. In genomics, we study thousands of variants, and treating each effect as random (with shared distributional properties) is much more realistic than assuming each has a fixed, unknown value.</p>
<section id="generate-simulated-data">
<h2>Generate Simulated Data<a class="headerlink" href="#generate-simulated-data" title="Link to this heading">#</a></h2>
<p>First, let’s recreate the exact same genetic data from our previous <a class="reference external" href="https://statfungen.github.io/statgen-primer/likelihood.html">Lecture: likelihood</a> analysis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Clear the environment</span>
<span class="nf">rm</span><span class="p">(</span><span class="n">list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">ls</span><span class="p">())</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">19</span><span class="p">)</span><span class="w">  </span><span class="c1"># For reproducibility</span>

<span class="c1"># Generate genotype data for 5 individuals at 1 variant</span>
<span class="n">N</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span>
<span class="n">genotypes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;CC&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;CT&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;TT&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;CT&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;CC&quot;</span><span class="p">)</span><span class="w">  </span><span class="c1"># Individual genotypes</span>
<span class="nf">names</span><span class="p">(</span><span class="n">genotypes</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Individual&quot;</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">N</span><span class="p">)</span>

<span class="c1"># Define alternative allele</span>
<span class="n">alt_allele</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&quot;T&quot;</span>

<span class="c1"># Convert to additive genotype coding (count of alternative alleles)</span>
<span class="n">Xraw_additive</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">numeric</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">alleles</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">strsplit</span><span class="p">(</span><span class="n">genotypes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="p">)[[</span><span class="m">1</span><span class="p">]]</span>
<span class="w">  </span><span class="n">Xraw_additive</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">alleles</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">alt_allele</span><span class="p">)</span>
<span class="p">}</span>
<span class="nf">names</span><span class="p">(</span><span class="n">Xraw_additive</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">genotypes</span><span class="p">)</span>

<span class="c1"># Standardize genotypes</span>
<span class="n">X</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">scale</span><span class="p">(</span><span class="n">Xraw_additive</span><span class="p">,</span><span class="w"> </span><span class="n">center</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)[,</span><span class="m">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set true beta and generate phenotype data</span>
<span class="n">true_beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.4</span>
<span class="n">true_sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1.0</span>

<span class="c1"># Generate phenotype with true effect</span>
<span class="n">Y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">true_beta</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">true_sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="bayesian-normal-mean-model-setup">
<h2>Bayesian Normal Mean Model Setup<a class="headerlink" href="#bayesian-normal-mean-model-setup" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Step 1: Data Model (What we observe)
Each person’s phenotype follows:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
Y_i | \beta, \sigma^2 \sim \text{Normal}(X_i \beta, \sigma^2)
\]</div>
<ol class="arabic simple" start="2">
<li><p>Effect Model (The effect is random)
Instead of assuming <span class="math notranslate nohighlight">\(\beta\)</span> is fixed, we model it as random:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\beta | \sigma_0^2 \sim \text{Normal}(0, \sigma_0^2)
\]</div>
<p>This says: “We expect the effect to center around 0, but with uncertainty <span class="math notranslate nohighlight">\(\sigma_0^2\)</span>”</p>
<ol class="arabic simple" start="3">
<li><p>Learning the Uncertainty (Hyperparameter estimation)</p></li>
</ol>
<p>We don’t just guess <span class="math notranslate nohighlight">\(\sigma_0^2\)</span> - we estimate it from the data itself!</p>
<section id="estimating-both-variances-from-data">
<h3>Estimating Both Variances from Data<a class="headerlink" href="#estimating-both-variances-from-data" title="Link to this heading">#</a></h3>
<p>We can first estimate <strong>both</strong> <span class="math notranslate nohighlight">\(\sigma^2\)</span> (error variance) and <span class="math notranslate nohighlight">\(\sigma_0^2\)</span> (prior variance) from the data itself.</p>
<p>The <strong>marginal likelihood</strong> (probability of observing our data, averaging over all possible β values) is:</p>
<div class="math notranslate nohighlight">
\[
P(Y | \sigma^2, \sigma_0^2) = \int P(Y | \beta, \sigma^2) P(\beta | \sigma_0^2) d\beta
\]</div>
<p>For our normal-normal model, this integral has a closed form! The marginal distribution of Y is:</p>
<div class="math notranslate nohighlight">
\[
Y \sim \text{Normal}(0, \sigma^2 I + \sigma_0^2 XX^T)
\]</div>
<p>We can use this to find the <span class="math notranslate nohighlight">\(\sigma^2\)</span> and <span class="math notranslate nohighlight">\(\sigma_0^2\)</span> that make our observed data most likely.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Function to compute log marginal likelihood for given parameters</span>
<span class="n">log_marginal_likelihood</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sigma_squared</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">params</span><span class="p">[</span><span class="m">1</span><span class="p">]</span>
<span class="w">  </span><span class="n">sigma_0_squared</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">params</span><span class="p">[</span><span class="m">2</span><span class="p">]</span>
<span class="w">  </span>
<span class="w">  </span><span class="c1"># Check for valid parameters</span>
<span class="w">  </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">sigma_squared</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">sigma_0_squared</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w"> </span><span class="kr">return</span><span class="p">(</span><span class="o">-</span><span class="kc">Inf</span><span class="p">)</span>
<span class="w">  </span>
<span class="w">  </span><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="w">  </span>
<span class="w">  </span><span class="c1"># Variance matrix: $\sigma^2$I + $\sigma_0^2$XX^T</span>
<span class="w">  </span><span class="n">var_matrix</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sigma_squared</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">diag</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">sigma_0_squared</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">outer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="p">)</span>
<span class="w">  </span>
<span class="w">  </span><span class="c1"># Compute log likelihood of multivariate normal</span>
<span class="w">  </span><span class="nf">tryCatch</span><span class="p">({</span>
<span class="w">    </span><span class="n">log_det</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">determinant</span><span class="p">(</span><span class="n">var_matrix</span><span class="p">,</span><span class="w"> </span><span class="n">logarithm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="o">$</span><span class="n">modulus</span>
<span class="w">    </span><span class="n">quad_form</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">t</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="nf">solve</span><span class="p">(</span><span class="n">var_matrix</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Y</span>
<span class="w">    </span>
<span class="w">    </span><span class="c1"># Log likelihood (ignoring constants)</span>
<span class="w">    </span><span class="m">-0.5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">log_det</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">quad_form</span><span class="p">)</span>
<span class="w">  </span><span class="p">},</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="kc">Inf</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Find optimal parameters by maximizing marginal likelihood</span>
<span class="nf">library</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>
<span class="n">optimize_result</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">optim</span><span class="p">(</span>
<span class="w">  </span><span class="n">par</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0.5</span><span class="p">),</span><span class="w">  </span><span class="c1"># Initial guesses for $\sigma^2$ and $\sigma_0^2$</span>
<span class="w">  </span><span class="n">fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">params</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="nf">log_marginal_likelihood</span><span class="p">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="p">),</span><span class="w">  </span><span class="c1"># Minimize negative log-likelihood</span>
<span class="w">  </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;L-BFGS-B&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.01</span><span class="p">,</span><span class="w"> </span><span class="m">0.01</span><span class="p">),</span>
<span class="w">  </span><span class="n">upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">sigma_squared_mle</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">optimize_result</span><span class="o">$</span><span class="n">par</span><span class="p">[</span><span class="m">1</span><span class="p">]</span>
<span class="n">sigma_0_squared_mle</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">optimize_result</span><span class="o">$</span><span class="n">par</span><span class="p">[</span><span class="m">2</span><span class="p">]</span>
<span class="n">sigma_mle</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">sigma_squared_mle</span><span class="p">)</span>
<span class="n">sigma_0_mle</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">sigma_0_squared_mle</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Estimated sigma^2 (error variance):&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">sigma_squared_mle</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Estimated sigma_0^2 (prior variance):&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">sigma_0_squared_mle</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimated sigma^2 (error variance): 0.663&quot;
[1] &quot;Estimated sigma_0^2 (prior variance): 0.01&quot;
</pre></div>
</div>
</div>
</div>
</section>
<section id="computing-the-posterior">
<h3>Computing the Posterior<a class="headerlink" href="#computing-the-posterior" title="Link to this heading">#</a></h3>
<p>Now that we’ve estimated our uncertainty about β from the data itself, we can compute the posterior distribution.</p>
<p><strong>The beauty of conjugacy</strong>: When we combine our normal prior with the normal likelihood, we get a normal posterior with simple formulas:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate sufficient statistics</span>
<span class="n">sum_X_squared</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">X</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="n">sum_XY</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">X</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Y</span><span class="p">)</span>

<span class="c1"># Posterior parameters using estimated variances</span>
<span class="n">posterior_variance</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">sum_X_squared</span><span class="o">/</span><span class="n">sigma_squared_mle</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="n">sigma_0_squared_mle</span><span class="p">)</span>
<span class="n">posterior_mean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">posterior_variance</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">sum_XY</span><span class="o">/</span><span class="n">sigma_squared_mle</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">0</span><span class="o">/</span><span class="n">sigma_0_squared_mle</span><span class="p">)</span>
<span class="n">posterior_sd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">posterior_variance</span><span class="p">)</span>

<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;\nPosterior Results:\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;beta | D ~ Normal(&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">posterior_mean</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;, &quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">posterior_variance</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;)\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Posterior mean:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">posterior_mean</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Posterior SD:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">posterior_sd</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Posterior Results:
beta | D ~ Normal( 0.018 ,  0.0094 )
Posterior mean: 0.018 
Posterior SD: 0.097 
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="supplementary">
<h1>Supplementary<a class="headerlink" href="#supplementary" title="Link to this heading">#</a></h1>
<section id="id1">
<h2>Graphical Summary<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>

<span class="c1"># Set parameters</span>
<span class="c1"># Prior: N(mu_0, sigma_0^2)</span>
<span class="n">mu_0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">      </span><span class="c1"># Prior mean</span>
<span class="n">sigma_0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">   </span><span class="c1"># Prior standard deviation (smaller = more informative prior)</span>

<span class="c1"># Data (observed values)</span>
<span class="n">y_obs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="m">2.1</span><span class="p">,</span><span class="w"> </span><span class="m">1.8</span><span class="p">,</span><span class="w"> </span><span class="m">2.3</span><span class="p">,</span><span class="w"> </span><span class="m">1.9</span><span class="p">)</span><span class="w">  </span><span class="c1"># Sample data</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span>
<span class="n">y_bar</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span><span class="w">  </span><span class="c1"># Sample mean</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">4</span><span class="w">  </span><span class="c1"># Known likelihood standard deviation (larger = less informative data)</span>

<span class="c1"># Calculate posterior parameters (conjugate normal-normal case)</span>
<span class="c1"># Posterior precision = prior precision + likelihood precision</span>
<span class="n">tau_0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sigma_0</span><span class="o">^</span><span class="m">2</span><span class="w">    </span><span class="c1"># Prior precision</span>
<span class="n">tau_likelihood</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sigma</span><span class="o">^</span><span class="m">2</span><span class="w">  </span><span class="c1"># Likelihood precision</span>
<span class="n">tau_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tau_0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tau_likelihood</span><span class="w">  </span><span class="c1"># Posterior precision</span>

<span class="c1"># Posterior parameters</span>
<span class="n">sigma_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tau_1</span><span class="p">)</span><span class="w">  </span><span class="c1"># Posterior standard deviation</span>
<span class="n">mu_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">tau_0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">mu_0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tau_likelihood</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">y_bar</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tau_1</span><span class="w">  </span><span class="c1"># Posterior mean</span>

<span class="c1"># Create data for plotting</span>
<span class="n">beta_range</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">-4</span><span class="p">,</span><span class="w"> </span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span>

<span class="c1"># Calculate densities</span>
<span class="n">prior_density</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dnorm</span><span class="p">(</span><span class="n">beta_range</span><span class="p">,</span><span class="w"> </span><span class="n">mu_0</span><span class="p">,</span><span class="w"> </span><span class="n">sigma_0</span><span class="p">)</span>
<span class="n">likelihood_density</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dnorm</span><span class="p">(</span><span class="n">beta_range</span><span class="p">,</span><span class="w"> </span><span class="n">y_bar</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span><span class="w">  </span><span class="c1"># Likelihood as function of beta</span>
<span class="n">posterior_density</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">dnorm</span><span class="p">(</span><span class="n">beta_range</span><span class="p">,</span><span class="w"> </span><span class="n">mu_1</span><span class="p">,</span><span class="w"> </span><span class="n">sigma_1</span><span class="p">)</span>

<span class="c1"># Combine into data frame</span>
<span class="n">plot_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="w">  </span><span class="n">beta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="n">beta_range</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span>
<span class="w">  </span><span class="n">density</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">prior_density</span><span class="p">,</span><span class="w"> </span><span class="n">likelihood_density</span><span class="p">,</span><span class="w"> </span><span class="n">posterior_density</span><span class="p">),</span>
<span class="w">  </span><span class="n">distribution</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Prior&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Likelihood&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Posterior&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">beta_range</span><span class="p">))</span>
<span class="p">)</span>

<span class="c1"># Create the plot</span>
<span class="n">p</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">ggplot</span><span class="p">(</span><span class="n">plot_data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">density</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">distribution</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">distribution</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Prior&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;tomato&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">                               </span><span class="s">&quot;Likelihood&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;#000080&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">                               </span><span class="s">&quot;Posterior&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkgreen&quot;</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_linetype_manual</span><span class="p">(</span><span class="n">values</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Prior&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                  </span><span class="s">&quot;Likelihood&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dotted&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                  </span><span class="s">&quot;Posterior&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;solid&quot;</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span>
<span class="w">    </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Density&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">expression</span><span class="p">(</span><span class="n">beta</span><span class="p">),</span>
<span class="w">    </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Distribution&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Distribution&quot;</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">(</span><span class="n">base_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span>
<span class="w">    </span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_blank</span><span class="p">(),</span>
<span class="w">    </span><span class="n">axis.title.y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.title.x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.text.x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.text.y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">legend.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_blank</span><span class="p">(),</span>
<span class="w">    </span><span class="n">legend.text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bottom&quot;</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">guides</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">guide_legend</span><span class="p">(</span><span class="n">override.aes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.5</span><span class="p">)))</span>

<span class="c1"># Add vertical lines for means</span>
<span class="n">p</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu_0</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;tomato&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_bar</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dotted&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu_1</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkgreen&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;solid&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">)</span>

<span class="c1"># Display plot</span>
<span class="nf">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="c1"># Save plot to file</span>
<span class="nf">ggsave</span><span class="p">(</span><span class="s">&quot;./cartoons/Bayesian_normal_mean_model.png&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">plot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">,</span>
<span class="w">       </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span><span class="p">,</span><span class="w"> </span>
<span class="w">       </span><span class="n">bg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;transparent&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">dpi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">300</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/37191fec1664c3ca77432a35913e5a7a455677f1505774a5a3bde54f300417d8.png"><img alt="_images/37191fec1664c3ca77432a35913e5a7a455677f1505774a5a3bde54f300417d8.png" src="_images/37191fec1664c3ca77432a35913e5a7a455677f1505774a5a3bde54f300417d8.png" style="width: 420px; height: 420px;" />
</a>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="p_value.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">p-value and Bayesian Hypothesis Testing</p>
      </div>
    </a>
    <a class="right-next"
       href="Bayesian_multivariate_normal_mean_model.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bayesian Multivariate Normal Mean Model</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Bayesian Normal Mean Model</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#graphical-summary">Graphical Summary</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#key-formula">Key Formula</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-details">Technical Details</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bayesian-perspective-uncertainty-as-random-variables">The Bayesian Perspective: Uncertainty as Random Variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-assumptions">Model Assumptions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-distribution-quantifying-our-uncertainty">Prior Distribution: Quantifying Our Uncertainty</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-what-we-can-condition-on">Likelihood: What We Can Condition On</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-distribution-conditioning-on-everything-available">Posterior Distribution: Conditioning on Everything Available</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation-as-weighted-average">Interpretation as Weighted Average</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-this-makes-sense">Why This Makes Sense</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#related-topics">Related Topics</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-simulated-data">Generate Simulated Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-normal-mean-model-setup">Bayesian Normal Mean Model Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-both-variances-from-data">Estimating Both Variances from Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-the-posterior">Computing the Posterior</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#supplementary">Supplementary</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Graphical Summary</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Wang, Rui Dong
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>